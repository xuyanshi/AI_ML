{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个练习中，我们使用电信企业的客户流失数据集，Orange_Telecom_Churn_Data.csv（存放在当前目录下）。我们先读入数据集，做一些数据预处理，然后使用各种模型根据用户的特点来预测其是否会流失。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一步：读入和处理数据\n",
    "* 读入数据集，并查看其基本信息。\n",
    "* 去除其中对预测无用的列，如“state\"，\"area_code\"和\"phone_number\"\n",
    "* 把'intl_plan'和'voice_mail_plan'两列的值转换成布尔类型：'yes'替换成'True'，'no'替换成'False’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入数据集，并查看其基本信息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除“state\"，\"area_code\"和\"phone_number\"三列\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把'intl_plan'和'voice_mail_plan'两列的值转换成布尔类型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二步：生成X和y\n",
    "* 将\"churned\"列之外的所有列作为X, \"churned\"列作为y\n",
    "* 检查y列中所有类别的个数\n",
    "* 划分成训练集和测试集\n",
    "* 分别检查训练集和测试集中所有类别的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成X和y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查y中所有类别的个数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分成训练集和测试集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别检查训练集和测试集中所有类别的个数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三步：随机森林\n",
    "* 将决策树个数设置为一个范围内的多个不同的值，分别训练出不同的随机森林，并计算每个森林的袋外错误\n",
    "* 将袋外错误作为决策树个数的函数，绘制在一张图上\n",
    "* 使用带交叉验证的网格搜索自动为随机森林模型搜索一个最佳决策树个数\n",
    "* 预测测试数据，并输出其精度、查准率、查全率和F1分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将决策树的个数设置为一个范围内的多个不同的值，分别训练出不同的随机森林，并计算每个森林的袋外错误\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将袋外错误作为决策树个数的函数，绘制在一张图上\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用带交叉验证的网格搜索自动为随机森林模型搜索一个最佳决策树个数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测测试数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出测试集上预测结果的精度、查准率、查全率和F1分数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第四步：AdaBoost\n",
    "* 使用带交叉验证的网格搜索训练一个最佳的AdaBoost模型，可以尝试调节参数：树的个数、学习率等\n",
    "* 预测测试数据，并输出其精度、查准率、查全率和F1分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用带交叉验证的网格搜索训练一个最佳的AdaBoost模型，可以尝试调节参数：树的个数、学习率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测测试数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出测试集上预测结果的精度、查准率、查全率和F1分数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第五步：Gradient Boost\n",
    "* 使用带交叉验证的网格搜索训练一个最佳的Gradient Boosting模型，可以尝试调节参数：树的个数、学习率、子采样、最大特征数等\n",
    "* 预测测试数据，并输出其精度、查准率、查全率和F1分数，并和AdaBoost模型做比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用带交叉验证的网格搜索训练一个最佳的Gradient Boosting模型，可以尝试调节参数：树的个数、学习率、子采样、最大特征数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测测试数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出测试集上预测结果的精度、查准率、查全率和F1分数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第六步：堆叠模型\n",
    "* 从前面训练出的随机森林、AdaBoost和Gradient Boosting模型中任取三个不同的模型，堆叠成一个模型，并拟合训练数据\n",
    "* 对测试数据进行预测\n",
    "* 输出测试集上预测结果的精度、查准率、查全率和F1分数，并分析比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从前面训练出的随机森林、AdaBoost和Gradient Boosting模型中任取三个不同的模型，堆叠成一个模型，并拟合训练数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测测试数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出测试集上预测结果的精度、查准率、查全率和F1分数，并分析比较\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
